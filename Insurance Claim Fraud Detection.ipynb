{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbb4b783",
   "metadata": {},
   "source": [
    "# Insurance Claims Fraud Detection Project\n",
    "\n",
    "Problem Statement:\n",
    "Business case:\n",
    "\n",
    "Insurance fraud is a huge problem in the industry. It's difficult to identify fraud claims. Machine Learning is in a unique position to help the Auto Insurance industry with this problem.\n",
    "\n",
    "In this project, you are provided a dataset which has the details of the insurance policy along with the customer details. It also has the details of the accident on the basis of which the claims have been made.\n",
    "\n",
    "In this example, you will be working with some auto insurance data to demonstrate how you can create a predictive model that predicts if an insurance claim is fraudulent or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140ea89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import missingno\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.stats import zscore\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922db544",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/dsrscientist/Data-Science-ML-Capstone-Projects/master/Automobile_insurance_fraud.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0161c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df # checking the first 5 and last 5 rows of our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aff8d5e",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac40834",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954997fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17d9236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique().to_frame(\"Unique Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e06f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"policy_number\", \"incident_location\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577919aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4997eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"_c39\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0515d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingno.bar(df, figsize = (25,5), color=\"tab:green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b836b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Rows and Columns before dropping duplicates: \", df.shape)\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f\"Rows and Columns after dropping duplicates: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df7b88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ccd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting list of all object data type column names\n",
    "object_datatype = []\n",
    "for x in df.dtypes.index:\n",
    "    if df.dtypes[x] == 'O':\n",
    "        object_datatype.append(x)\n",
    "print(f\"Object Data Type Columns are:\\n \",object_datatype)\n",
    "\n",
    "# getting the list of all numeric data type column names\n",
    "number_datatype = []\n",
    "for x in df.dtypes.index:\n",
    "    if df.dtypes[x] == 'float64' or df.dtypes[x] == 'int64':\n",
    "        number_datatype.append(x)\n",
    "print(f\"\\nNumber Data Type Columns are:\\n \",number_datatype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f968aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c18657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the statistical description of numeric datatype columns\n",
    "\n",
    "plt.figure(figsize = (15,9))\n",
    "sns.heatmap(round(df.describe()[1:].transpose(),2), linewidth = 2, annot= True, fmt = \".4f\", cmap=\"hot\")\n",
    "plt.title(\"Satistical Report of Numerical Columns\")\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b4c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418de79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in object_datatype:\n",
    "    print(col)\n",
    "    print(df[col].value_counts())\n",
    "    print(\"=\"*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f562cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[object_datatype].nunique().to_frame(\"Unique Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bac391",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[number_datatype].nunique().to_frame(\"Unique Values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bd5d0b",
   "metadata": {},
   "source": [
    "# Data Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7e3dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the Date column into seperate day - month -  year columns using pandas Datetime method\n",
    "df['policy_bind_date'] = pd.to_datetime(df['policy_bind_date'])\n",
    "df['policy_bind_Day'] = df['policy_bind_date'].apply(lambda x:x.day)\n",
    "df['policy_bind_Month'] = df['policy_bind_date'].apply(lambda x:x.month)\n",
    "df['policy_bind_Year'] = df['policy_bind_date'].apply(lambda x:x.year)\n",
    "\n",
    "# separating the Date column into seperate day - month -  year columns using pandas Datetime method\n",
    "df['incident_date'] = pd.to_datetime(df['incident_date'])\n",
    "df['incident_Day'] = df['incident_date'].apply(lambda x:x.day)\n",
    "df['incident_Month'] = df['incident_date'].apply(lambda x:x.month)\n",
    "df['incident_Year'] = df['incident_date'].apply(lambda x:x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c2a4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the original Date columns after separating the desired outputs\n",
    "df.drop(columns = ['policy_bind_date','incident_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6b0744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the \"?\" filled rows with a meaningful name of \"questionable\"\n",
    "df['collision_type'] = df['collision_type'].replace('?', 'questionable')\n",
    "df['property_damage'] = df['property_damage'].replace('?', 'questionable')\n",
    "df['police_report_available'] = df['police_report_available'].replace('?', 'questionable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7da8fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for any missing data and if yes then it's percentage\n",
    "for col in df:\n",
    "    percentage = np.round((df[col].isnull().sum()/1000)*100, 2)\n",
    "    print(col, \":\".format(), percentage, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3c9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique().to_frame(\"Unique Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b2fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"incident_Year\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24ae5e1",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b01d152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pie(x):\n",
    "    plt.style.use('seaborn-white')\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.pie(x.value_counts(), labels=x.value_counts().index, shadow=True, autopct='%1.2f%%')\n",
    "    plt.legend(prop={'size':14})\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    return plt.show()\n",
    "\n",
    "col1 = ['fraud_reported', 'insured_sex', 'policy_state', 'policy_csl', 'policy_deductable', 'bodily_injuries',\n",
    "        'police_report_available', 'property_damage', 'incident_type', 'collision_type', 'incident_severity',\n",
    "        'number_of_vehicles_involved', 'witnesses', 'authorities_contacted', 'insured_relationship',\n",
    "        'insured_education_level', 'incident_state', 'incident_city']\n",
    "\n",
    "for i in df[col1]:\n",
    "    print(f\"Single digit category column name:\", i)\n",
    "    generate_pie(df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b8dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_countplot(x):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    sns.countplot(x)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    return plt.show()\n",
    "\n",
    "col2 = ['umbrella_limit', 'insured_occupation', 'auto_make', 'insured_hobbies', 'auto_model']\n",
    "\n",
    "for j in df[col2]:\n",
    "    print(f\"Double digit category column name:\", j)\n",
    "    generate_countplot(df[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f81831",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-bright')\n",
    "\n",
    "col1.remove(\"fraud_reported\")\n",
    "\n",
    "for k in df[col1]:\n",
    "    plt.figure(figsize=(15,8))\n",
    "    print(f\"{k} vs fraud_reported column ->\")\n",
    "    sns.countplot(df[k])\n",
    "    sns.countplot(df[k], hue=df['fraud_reported'])\n",
    "    plt.show()\n",
    "    \n",
    "for l in df[col2]:\n",
    "    plt.figure(figsize=(15,8))\n",
    "    print(f\"{l} vs fraud_reported column ->\")\n",
    "    sns.countplot(df[l])\n",
    "    sns.countplot(df[l], hue=df['fraud_reported'])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56bd2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "col3 = ['incident_hour_of_the_day', 'age', 'capital-gains', 'capital-loss', 'months_as_customer', 'property_claim',\n",
    "       'injury_claim', 'vehicle_claim', 'total_claim_amount', 'policy_annual_premium', 'insured_zip']\n",
    "\n",
    "for z in df[col3]:\n",
    "    fig = plt.figure(figsize=(10,7))\n",
    "    ax=sns.kdeplot(df.loc[(df['fraud_reported'] == 'N'),z], color='b', shade=True, label='Not Fraud') \n",
    "    ax=sns.kdeplot(df.loc[(df['fraud_reported'] == 'Y'),z], color='r', shade=True, label='Fraud')\n",
    "    plt.title('Fraud rate with respect to {}'.format(z))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cc8015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting list of all object data type column names\n",
    "object_datatype = []\n",
    "for x in df.dtypes.index:\n",
    "    if df.dtypes[x] == 'O':\n",
    "        object_datatype.append(x)\n",
    "print(f\"Object Data Type Columns are:\\n\", object_datatype)\n",
    "\n",
    "object_datatype.remove('fraud_reported')\n",
    "object_datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721b2ba9",
   "metadata": {},
   "source": [
    "# Encoding the categorical object datatype columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaa4578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df[\"fraud_reported\"] = le.fit_transform(df[\"fraud_reported\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323d43dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Encoder\n",
    "\n",
    "oe = OrdinalEncoder()\n",
    "def ordinal_encode(df, column):\n",
    "    df[column] = oe.fit_transform(df[column])\n",
    "    return df\n",
    "\n",
    "df=ordinal_encode(df, object_datatype)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b599db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of our data frame post encoding is\", df.shape)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76adc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fast')\n",
    "\n",
    "fig, ax = plt.subplots(ncols=11, nrows=1, figsize=(15,7))\n",
    "index = 0\n",
    "ax = ax.flatten()\n",
    "for col, value in df[col3].items():\n",
    "    sns.boxenplot(y=col, data=df, ax=ax[index], color=\"purple\")\n",
    "    index += 1\n",
    "plt.tight_layout(pad=0.4, w_pad=0.4, h_pad=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc1f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866abc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=6, nrows=2, figsize=(15,10))\n",
    "index = 0\n",
    "ax = ax.flatten()\n",
    "for col, value in df[col3].items():\n",
    "    sns.distplot(value, ax=ax[index], hist=False, color=\"g\", kde_kws={\"shade\": True})\n",
    "    index += 1\n",
    "plt.tight_layout(pad=0.4, w_pad=0.4, h_pad=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9400e92",
   "metadata": {},
   "source": [
    "# Using Z Score to remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68541278",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.abs(zscore(df))\n",
    "threshold = 3\n",
    "df1 = df[(z<3).all(axis = 1)]\n",
    "\n",
    "print (\"Shape of the dataframe before removing outliers: \", df.shape)\n",
    "print (\"Shape of the dataframe after removing outliers: \", df1.shape)\n",
    "print (\"Percentage of data loss post outlier removal: \", (df.shape[0]-df1.shape[0])/df.shape[0]*100)\n",
    "\n",
    "df=df1.copy() # reassigning the changed dataframe name to our original dataframe name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd56793",
   "metadata": {},
   "source": [
    "# Using Log Transform to fix skewness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be21947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in number_datatype:\n",
    "    if df.skew().loc[col]>0.55:\n",
    "        df[col]=np.log1p(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f6bd2b",
   "metadata": {},
   "source": [
    "# Correlation using a Heatmap\n",
    "\n",
    "Positive correlation - A correlation of +1 indicates a perfect positive correlation, meaning that both variables move in the same direction together.\n",
    "\n",
    "Negative correlation - A correlation of –1 indicates a perfect negative correlation, meaning that as one variable goes up, the other goes down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1950203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-pastel')\n",
    "\n",
    "upper_triangle = np.triu(df.corr())\n",
    "plt.figure(figsize=(25,25))\n",
    "sns.heatmap(df.corr(), vmin=-1, vmax=1, annot=True, square=True, fmt='0.3f', \n",
    "            annot_kws={'size':8}, cmap=\"plasma\", mask=upper_triangle)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7dd296",
   "metadata": {},
   "source": [
    "# Correlation Bar Plot comparing features with our label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8472ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-white')\n",
    "\n",
    "df_corr = df.corr()\n",
    "plt.figure(figsize=(15,8))\n",
    "df_corr['fraud_reported'].sort_values(ascending=False).drop('fraud_reported').plot.bar()\n",
    "plt.title(\"Correlation of Features vs Income Label\\n\", fontsize=16)\n",
    "plt.xlabel(\"\\nFeatures List\", fontsize=14)\n",
    "plt.ylabel(\"Correlation Value\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c23719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb69322a",
   "metadata": {},
   "source": [
    "# Splitting the dataset into 2 variables namely 'X' and 'Y' for feature and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99501d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('fraud_reported', axis=1)\n",
    "Y = df['fraud_reported']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851ba1ab",
   "metadata": {},
   "source": [
    "# Resolving the class imbalance issue in our label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5eb713",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1957acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding samples to make all the categorical label values same\n",
    "\n",
    "oversample = SMOTE()\n",
    "X, Y = oversample.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631b5aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28311839",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6896eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d09acf0",
   "metadata": {},
   "source": [
    "# finding best random state for building our Classification Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b14906",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxAccu=0\n",
    "maxRS=0\n",
    "\n",
    "for i in range(1, 1000):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=i)\n",
    "    lr=LogisticRegression()\n",
    "    lr.fit(X_train, Y_train)\n",
    "    pred = lr.predict(X_test)\n",
    "    acc_score = (accuracy_score(Y_test, pred))*100\n",
    "    \n",
    "    if acc_score>maxAccu:\n",
    "        maxAccu=acc_score\n",
    "        maxRS=i\n",
    "\n",
    "print(\"Best accuracy score is\", maxAccu,\"on Random State\", maxRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f72801",
   "metadata": {},
   "source": [
    "# Feature importance bar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61e5eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()\n",
    "rf.fit(X_train, Y_train)\n",
    "importances = pd.DataFrame({'Features':X.columns, 'Importance':np.round(rf.feature_importances_,3)})\n",
    "importances = importances.sort_values('Importance', ascending=False).set_index('Features')\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c830242d",
   "metadata": {},
   "source": [
    "# Machine Learning Models for classification with Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88d29e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Model Function\n",
    "\n",
    "def classify(model, X, Y):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=213)\n",
    "    \n",
    "    # Training the model\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Predicting Y_test\n",
    "    pred = model.predict(X_test)\n",
    "    \n",
    "    # Classification Report\n",
    "    class_report = classification_report(Y_test, pred)\n",
    "    print(\"\\nClassification Report:\\n\", class_report)\n",
    "    \n",
    "    # Accuracy Score\n",
    "    acc_score = (accuracy_score(Y_test, pred))*100\n",
    "    print(\"Accuracy Score:\", acc_score)\n",
    "    \n",
    "    # Cross Validation Score\n",
    "    cv_score = (cross_val_score(model, X, Y, cv=5).mean())*100\n",
    "    print(\"Cross Validation Score:\", cv_score)\n",
    "    \n",
    "    # Result of accuracy minus cv scores\n",
    "    result = acc_score - cv_score\n",
    "    print(\"\\nAccuracy Score - Cross Validation Score is\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a057dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "model=LogisticRegression()\n",
    "classify(model, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56d7d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Classifier\n",
    "\n",
    "model=SVC(C=1.0, kernel='rbf', gamma='auto', random_state=42)\n",
    "classify(model, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c66b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "model=DecisionTreeClassifier(random_state=21, max_depth=15)\n",
    "classify(model, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1759fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "model=RandomForestClassifier(max_depth=15, random_state=111)\n",
    "classify(model, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e69c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Neighbors Classifier\n",
    "\n",
    "model=KNeighborsClassifier(n_neighbors=15)\n",
    "classify(model, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceb30ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Trees Classifier\n",
    "\n",
    "model=ExtraTreesClassifier()\n",
    "classify(model, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68ba189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB Classifier\n",
    "\n",
    "model=xgb.XGBClassifier(verbosity=0)\n",
    "classify(model, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1d61b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM Classifier\n",
    "\n",
    "model=lgb.LGBMClassifier()\n",
    "classify(model, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c01051",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning on the best Classification ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ba93f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing Extra Trees Classifier\n",
    "\n",
    "fmod_param = {'criterion' : ['gini', 'entropy'],\n",
    "              'n_jobs' : [-2, -1, 1],\n",
    "              'random_state' : [42, 213, 1000],\n",
    "              'max_depth' : [30, 40, 50],\n",
    "              'n_estimators' : [300, 500, 700]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc0ea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "GSCV = GridSearchCV(ExtraTreesClassifier(), fmod_param, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de20ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "GSCV.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440aa02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GSCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706e861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Model = ExtraTreesClassifier(criterion='gini', max_depth=30, n_estimators=300, n_jobs=-2, random_state=42)\n",
    "Classifier = Final_Model.fit(X_train, Y_train)\n",
    "fmod_pred = Final_Model.predict(X_test)\n",
    "fmod_acc = (accuracy_score(Y_test, fmod_pred))*100\n",
    "print(\"Accuracy score for the Best Model is:\", fmod_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507beb53",
   "metadata": {},
   "source": [
    "# AUC ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f426368",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-bright')\n",
    "\n",
    "disp = metrics.plot_roc_curve(Final_Model, X_test, Y_test)\n",
    "disp.figure_.suptitle(\"ROC Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97484e28",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad0a3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "\n",
    "class_names = df.columns\n",
    "metrics.plot_confusion_matrix(Classifier, X_test, Y_test, cmap='mako')\n",
    "plt.title('\\t Confusion Matrix for Decision Tree Classifier \\n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7206e19",
   "metadata": {},
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b857d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"FinalModel_E09.pkl\"\n",
    "joblib.dump(Final_Model, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
